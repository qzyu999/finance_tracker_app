{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftotext\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import gspread\n",
    "\n",
    "BANK_STATEMENTS_FILE_PATH='/Users/jaredyu/Desktop/finances/finance_tracker_app/data/bank_statements'\n",
    "CREDIT_CARD_STATEMENTS_FILE_PATH='/Users/jaredyu/Desktop/finances/finance_tracker_app/data/credit_card_statements'\n",
    "SPREADSHEET_KEY=os.environ['SPREADSHEET_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Reference Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_date_df = pd.DataFrame({\n",
    "    'update_date': [\n",
    "        '05/27/2024'\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1CAyyf2kr-pS7LNX1a_0ithw6niL3Js3K4ZEOlwDViZY',\n",
       " 'replies': [{}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = gspread.service_account()\n",
    "finance_tracker_db_spreadsheet = gc.open_by_key(SPREADSHEET_KEY)\n",
    "update_reference_table_worksheet = finance_tracker_db_spreadsheet.worksheet('update_reference_table')\n",
    "update_reference_table_worksheet.update([update_date_df.columns.values.tolist()] + update_date_df.values.tolist())\n",
    "update_reference_table_worksheet.format(\"C:D\", {\"numberFormat\": {\"type\": \"DATE_TIME\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# East West Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDGE CASE: MULTI-PAGE STATEMENTS\n",
    "# EDGE CASE: MULTI-LINE TRANSACTIONS\n",
    "# EDGE CASE: CHECK DEPOSITS BREAK PYPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_sequentially(numbers):\n",
    "    # Check if the list has an even length\n",
    "    if len(numbers) % 2 != 0:\n",
    "        raise ValueError(\"The list must have an even length\")\n",
    "\n",
    "    # Create the list of pairs\n",
    "    paired_list = []\n",
    "    for i in range(0, len(numbers), 2):\n",
    "        paired_list.append(numbers[i:i+2])\n",
    "    \n",
    "    return paired_list\n",
    "\n",
    "def remove_indices(lst, indices):\n",
    "    # Sort indices in descending order to avoid reindexing issues\n",
    "    indices = sorted(indices, reverse=True)\n",
    "    \n",
    "    # Remove elements at each index\n",
    "    for index in indices:\n",
    "        if 0 <= index < len(lst):\n",
    "            lst.pop(index)\n",
    "        else:\n",
    "            raise IndexError(f\"Index {index} is out of bounds for list of length {len(lst)}\")\n",
    "    \n",
    "    return lst\n",
    "\n",
    "def has_consecutive_values(data):\n",
    "  \"\"\"\n",
    "  This function checks if a list contains any consecutive values (adjacent duplicates).\n",
    "\n",
    "  Args:\n",
    "      data: A list of any data type.\n",
    "\n",
    "  Returns:\n",
    "      True if there are consecutive values, False otherwise.\n",
    "  \"\"\"\n",
    "  if len(data) <= 1:\n",
    "    return False  # Need at least 2 elements for consecutive values\n",
    "\n",
    "  # Iterate through the list, checking for adjacent duplicates\n",
    "  for i in range(1, len(data)):\n",
    "    if data[i] == data[i-1] + 1:\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "def concatenate_multi_line_transactions(transaction_lines_list, bank, year, month):\n",
    "    \"\"\"\n",
    "    Edit credit and debit line lists to concatenate strings from multi-line items.\n",
    "    \"\"\"\n",
    "    transaction_lines_list = transaction_lines_list.copy()\n",
    "    date_pattern = r\"^\\d{2}-\\d{2}$\"\n",
    "    bad_idx_list = []\n",
    "    for idx, txc_line in enumerate(transaction_lines_list):\n",
    "        if not bool(re.match(date_pattern, txc_line[:5])):\n",
    "            bad_idx_list.append(idx)\n",
    "\n",
    "    if has_consecutive_values(data=bad_idx_list):\n",
    "        raise Exception(f'Transactions with more than two lines found. Info: {bank}, {year}, {month}')\n",
    "\n",
    "    if len(bad_idx_list) > 0:\n",
    "        complete_bad_idx_list = []\n",
    "        for i in bad_idx_list:\n",
    "            complete_bad_idx_list.append(i - 1)\n",
    "            complete_bad_idx_list.append(i)\n",
    "\n",
    "        paired_short_line_list = pair_sequentially(complete_bad_idx_list)\n",
    "\n",
    "        # extract them from the original list and concatenate them together\n",
    "        combined_line_list = []\n",
    "        for paired_lines in paired_short_line_list:\n",
    "            combined_line = ''.join(transaction_lines_list[paired_lines[0]:paired_lines[1]+1])\n",
    "            combined_line_list.append(combined_line)\n",
    "\n",
    "        # drop the original items\n",
    "        transaction_lines_list = remove_indices(transaction_lines_list, complete_bad_idx_list)\n",
    "\n",
    "        return transaction_lines_list + combined_line_list\n",
    "    else:\n",
    "        return transaction_lines_list\n",
    "\n",
    "def parse_lines_with_regex(lines, transaction_pattern):\n",
    "    # Ref.: https://levelup.gitconnected.com/creating-a-bank-statement-parser-with-python-9223b895ebae\n",
    "    transactions = []\n",
    "    for line in lines:\n",
    "        match = re.search(pattern=transaction_pattern, string=line)\n",
    "        if match:\n",
    "            transactions.append(match.groupdict())\n",
    "\n",
    "    return pd.DataFrame(transactions)\n",
    "\n",
    "transaction_pattern = (\n",
    "        r\"(?P<transaction_date>\\d+-\\d+)\\s*\"\n",
    "        r\"(?P<description>.*?)\\s*\"\n",
    "        r\"(?P<amount>[\\d.,]+)$\"\n",
    ")\n",
    "\n",
    "def parse_east_west_bank_bank_statements_by_year(bank, year, bank_statements_file_path):\n",
    "    \"\"\"\n",
    "    Go through a year of monthly bank statements for a given bank and parse\n",
    "    the statements and return a df.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(bank_statements_file_path, bank, year)\n",
    "    monthly_bank_statement_list = os.listdir(file_path)\n",
    "    monthly_bank_statement_list = [i for i in monthly_bank_statement_list if i != '.DS_Store']\n",
    "    transactions_df_list = []\n",
    "\n",
    "    for monthly_bank_statement_file in monthly_bank_statement_list:\n",
    "        month = monthly_bank_statement_file.split('_')[1].split('.')[0]\n",
    "        with open(os.path.join(file_path, monthly_bank_statement_file), \"rb\") as file:\n",
    "            pdf = pdftotext.PDF(file, physical=True)\n",
    "            if len(pdf) == 2:\n",
    "                first_page = pdf[0]\n",
    "                lines1 = first_page.split(\"\\n\")\n",
    "                lines1 = [i.lstrip() for i in lines1]\n",
    "                lines1 = [i for i in lines1 if i != '']\n",
    "                lines2 = None\n",
    "            elif len(pdf) == 3:\n",
    "                first_page = pdf[0]\n",
    "                second_page = pdf[1]\n",
    "                lines1 = first_page.split(\"\\n\")\n",
    "                second_page = pdf[1]\n",
    "                lines2 = second_page.split(\"\\n\")\n",
    "\n",
    "                lines1 = [i.lstrip() for i in lines1]\n",
    "                lines1 = [i for i in lines1 if i != '']\n",
    "                lines2 = [i.lstrip() for i in lines2]\n",
    "                lines2 = [i for i in lines2 if i != '']\n",
    "            else:\n",
    "                pdf_length = len(pdf)\n",
    "                raise Exception(f'New length for pdf ({pdf_length}), time to set new rules. Info: {bank}, {year}, {month}')\n",
    "            \n",
    "            # for line in lines1:\n",
    "            #     print(line.lstrip())\n",
    "\n",
    "        try:\n",
    "            credits_line_idx = lines1.index('CREDITS')\n",
    "            credit_balance_exists = True\n",
    "        except:\n",
    "            credit_balance_exists = False\n",
    "        try:\n",
    "            debits_line_idx = lines1.index('DEBITS')\n",
    "            debits_line_on_first_page = True\n",
    "        except:\n",
    "            debits_line_on_first_page = False\n",
    "            raise Exception(f'DEBITS not on first page, time to set new rules. Info: {bank}, {year}, {month}')\n",
    "\n",
    "        try:\n",
    "            daily_balances_line_idx = lines1.index('DAILY BALANCES')\n",
    "            daily_balances_on_first_page = True\n",
    "        except:\n",
    "            daily_balances_line_idx = lines2.index('DAILY BALANCES')\n",
    "            daily_balances_on_first_page = False\n",
    "        credit_lines = lines1[credits_line_idx + 2:debits_line_idx]\n",
    "\n",
    "        try: # check if the DEBITS balance is multi-page\n",
    "            if len([i for i in lines2 if i[:4] == 'Date']) > 1:\n",
    "                debit_balance_multi_page = True\n",
    "            else:\n",
    "                debit_balance_multi_page = False\n",
    "        except:\n",
    "            debit_balance_multi_page = False\n",
    "\n",
    "        # No CREDITS and DEBITS does not extend to second\n",
    "        if not credit_balance_exists and not debit_balance_multi_page:\n",
    "            debit_lines = lines1[debits_line_idx + 2:daily_balances_line_idx]\n",
    "            debit_lines = concatenate_multi_line_transactions(debit_lines, bank, year, month)\n",
    "            debit_df = parse_lines_with_regex(lines=debit_lines, transaction_pattern=transaction_pattern)\n",
    "            debit_df['amount'] = debit_df['amount'].apply(lambda x: -1 * float(x.replace(',' , '')))\n",
    "\n",
    "            # debit_df['bank'] = bank\n",
    "            debit_df['year'] = year\n",
    "            debit_df['month'] = month\n",
    "            transactions_df_list.append(debit_df)\n",
    "            continue\n",
    "        # DAILY BALANCES on first page and DEBITS does not extend to second\n",
    "        elif daily_balances_on_first_page and not debit_balance_multi_page:\n",
    "            debit_lines = lines1[debits_line_idx + 2:daily_balances_line_idx]\n",
    "        # DEBITS on first page but extends to second\n",
    "        elif debits_line_on_first_page and debit_balance_multi_page:\n",
    "            second_page_debit_date_line_idx = lines2.index([i for i in lines2 if i[:4] == 'Date'][0])\n",
    "            debit_lines = lines1[debits_line_idx + 2:] + lines2[second_page_debit_date_line_idx + 1:daily_balances_line_idx]\n",
    "        # DAILY BALANCES not on first page and DEBITS does not extend to second\n",
    "        elif not daily_balances_on_first_page and not debit_balance_multi_page:\n",
    "            debit_lines = lines1[debits_line_idx + 2:]\n",
    "        else:\n",
    "            raise Exception(f'Uncaught case. Info: {bank}, {year}, {month}')\n",
    "\n",
    "        credit_lines = concatenate_multi_line_transactions(credit_lines, bank, year, month)\n",
    "        debit_lines = concatenate_multi_line_transactions(debit_lines, bank, year, month)\n",
    "\n",
    "        credit_df = parse_lines_with_regex(lines=credit_lines, transaction_pattern=transaction_pattern)\n",
    "        debit_df = parse_lines_with_regex(lines=debit_lines, transaction_pattern=transaction_pattern)\n",
    "\n",
    "        credit_df['amount'] = credit_df['amount'].apply(lambda x: float(x.replace(',' , '')))\n",
    "        debit_df['amount'] = debit_df['amount'].apply(lambda x: -1 * float(x.replace(',' , '')))\n",
    "\n",
    "        transactions_df = pd.concat([credit_df, debit_df])\n",
    "\n",
    "        # transactions_df['bank'] = bank\n",
    "        transactions_df['year'] = year\n",
    "        transactions_df['month'] = month\n",
    "        transactions_df_list.append(transactions_df)\n",
    "\n",
    "    combined_transactions_df = pd.concat(transactions_df_list)\n",
    "\n",
    "    return combined_transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "east_west_bank_annual_beginning_ending_balance_df = pd.DataFrame({\n",
    "    '2020': [2459.25, 15619.65],\n",
    "    '2021': [15619.65, 14552.04],\n",
    "    '2022': [14552.04, 3046.51],\n",
    "    '2023': [3046.51, 19634.88],\n",
    "    '2024': [19634.88, 2982.74],\n",
    "})\n",
    "\n",
    "# transactions_2019_df = parse_bank_statements_by_year(\n",
    "#     bank='east_west_bank',\n",
    "#     year='2019',\n",
    "#     bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    "# )\n",
    "\n",
    "transactions_2020_df = parse_east_west_bank_bank_statements_by_year(\n",
    "    bank='east_west_bank',\n",
    "    year='2020',\n",
    "    bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2021_df = parse_east_west_bank_bank_statements_by_year(\n",
    "    bank='east_west_bank',\n",
    "    year='2021',\n",
    "    bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2022_df = parse_east_west_bank_bank_statements_by_year(\n",
    "    bank='east_west_bank',\n",
    "    year='2022',\n",
    "    bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2023_df = parse_east_west_bank_bank_statements_by_year(\n",
    "    bank='east_west_bank',\n",
    "    year='2023',\n",
    "    bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2024_df = parse_east_west_bank_bank_statements_by_year(\n",
    "    bank='east_west_bank',\n",
    "    year='2024',\n",
    "    bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "\n",
    "def approx_sum(x):\n",
    "    return round(sum(x), 2)\n",
    "\n",
    "def test_annual_balance_east_west_bank(df, year, ref_df):\n",
    "    tmp = round(ref_df[year][0] + approx_sum(df['amount']), 2)\n",
    "    assert tmp == ref_df[year][1]\n",
    "\n",
    "# test for regressions\n",
    "test_annual_balance_east_west_bank(\n",
    "    df=transactions_2020_df,\n",
    "    year='2020',\n",
    "    ref_df=east_west_bank_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank(\n",
    "    df=transactions_2021_df,\n",
    "    year='2021',\n",
    "    ref_df=east_west_bank_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank(\n",
    "    df=transactions_2022_df,\n",
    "    year='2022',\n",
    "    ref_df=east_west_bank_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank(\n",
    "    df=transactions_2023_df,\n",
    "    year='2023',\n",
    "    ref_df=east_west_bank_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank(\n",
    "    df=transactions_2024_df,\n",
    "    year='2024',\n",
    "    ref_df=east_west_bank_annual_beginning_ending_balance_df\n",
    ")\n",
    "\n",
    "total_transactions_df = pd.concat([\n",
    "    transactions_2020_df,\n",
    "    transactions_2021_df,\n",
    "    transactions_2022_df,\n",
    "    transactions_2023_df,\n",
    "    transactions_2024_df\n",
    "])\n",
    "\n",
    "total_transactions_df['transaction_date_month'] = total_transactions_df['transaction_date'].apply(lambda x: x.split('-')[0])\n",
    "assert sum(total_transactions_df['transaction_date_month'] != total_transactions_df['month']) == 0\n",
    "total_transactions_df['transaction_date'] = total_transactions_df['year'] + '-' + total_transactions_df['transaction_date']\n",
    "total_transactions_df.drop(['year', 'month', 'transaction_date_month'], inplace=True, axis=1)\n",
    "total_transactions_df.sort_values(by=['transaction_date', 'amount', 'description'], ascending=[True, False, True], inplace=True)\n",
    "total_transactions_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>description</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>Deposit</td>\n",
       "      <td>510.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>Preauth Debit        VENMO PAYMENT 200106</td>\n",
       "      <td>-160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>Preauth Debit        VENMO PAYMENT 200106</td>\n",
       "      <td>-180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>Preauth Debit        VENMO PAYMENT 200106</td>\n",
       "      <td>-240.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>Preauth Debit        VENMO PAYMENT 200106</td>\n",
       "      <td>-370.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>Pre-Auth Credit             CPRIME INC DIRECT ...</td>\n",
       "      <td>5839.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>Preauth Debit        GOLDMAN SACHS BA COLLECTI...</td>\n",
       "      <td>-6300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>Pre-Auth Credit             CPRIME INC DIRECT ...</td>\n",
       "      <td>3235.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>Preauth Debit        GOLDMAN SACHS BA COLLECTI...</td>\n",
       "      <td>-3000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>Preauth Debit        DISCOVER E-PAYMENT 240424</td>\n",
       "      <td>-427.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    transaction_date                                        description  \\\n",
       "0         2020-01-02                                            Deposit   \n",
       "1         2020-01-06          Preauth Debit        VENMO PAYMENT 200106   \n",
       "2         2020-01-06          Preauth Debit        VENMO PAYMENT 200106   \n",
       "3         2020-01-06          Preauth Debit        VENMO PAYMENT 200106   \n",
       "4         2020-01-06          Preauth Debit        VENMO PAYMENT 200106   \n",
       "..               ...                                                ...   \n",
       "621       2024-04-08  Pre-Auth Credit             CPRIME INC DIRECT ...   \n",
       "622       2024-04-08  Preauth Debit        GOLDMAN SACHS BA COLLECTI...   \n",
       "623       2024-04-23  Pre-Auth Credit             CPRIME INC DIRECT ...   \n",
       "624       2024-04-23  Preauth Debit        GOLDMAN SACHS BA COLLECTI...   \n",
       "625       2024-04-24     Preauth Debit        DISCOVER E-PAYMENT 240424   \n",
       "\n",
       "      amount  \n",
       "0     510.00  \n",
       "1    -160.00  \n",
       "2    -180.00  \n",
       "3    -240.00  \n",
       "4    -370.00  \n",
       "..       ...  \n",
       "621  5839.26  \n",
       "622 -6300.00  \n",
       "623  3235.25  \n",
       "624 -3000.00  \n",
       "625  -427.16  \n",
       "\n",
       "[626 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1CAyyf2kr-pS7LNX1a_0ithw6niL3Js3K4ZEOlwDViZY',\n",
       " 'updatedRange': 'east_west_bank_bank_statements!A1:C627',\n",
       " 'updatedRows': 627,\n",
       " 'updatedColumns': 3,\n",
       " 'updatedCells': 1881}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = gspread.service_account()\n",
    "\n",
    "finance_tracker_db_spreadsheet = gc.open_by_key(SPREADSHEET_KEY)\n",
    "east_west_bank_worksheet = finance_tracker_db_spreadsheet.worksheet('east_west_bank_bank_statements')\n",
    "east_west_bank_worksheet.update([total_transactions_df.columns.values.tolist()] + total_transactions_df.values.tolist())\n",
    "# east_west_bank_worksheet.format(\"C:C\", {\"numberFormat\": {\"type\": \"CURRENCY\"}})\n",
    "# east_west_bank_worksheet.format(\"A\", {\"numberFormat\": {\"type\": \"DATE_TIME\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build some unit tests\n",
    "# create truth table, check for regressions\n",
    "# rules:\n",
    "# pdf generally has length +1, ignore last blank page\n",
    "# CREDITS should be in first page\n",
    "# DEBITS should be in first page (could be in second, haven't seen it)\n",
    "# DAILY BALANCES could be in first or second\n",
    "# some transactions are multi-line\n",
    "# capture the transactions under CREDITS and DEBITS correctly\n",
    "\n",
    "# get the beginning and ending balance per month/year in a reference table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marcus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lines_with_regex(lines, transaction_pattern):\n",
    "    # Ref.: https://levelup.gitconnected.com/creating-a-bank-statement-parser-with-python-9223b895ebae\n",
    "    transactions = []\n",
    "    for line in lines:\n",
    "        match = re.search(pattern=transaction_pattern, string=line)\n",
    "        if match:\n",
    "            transactions.append(match.groupdict())\n",
    "\n",
    "    return pd.DataFrame(transactions)\n",
    "\n",
    "transaction_pattern = (\n",
    "    r\"(?P<transaction_date>\\d+/\\d+/\\d+)\\s*\"\n",
    "    r\"(?P<description>.*?)(?=\\$)\"\n",
    "    r\"(?P<credit_debit>.*?)(?=\\s)\\s*\"\n",
    "    r\"(?P<balance>.*)\"\n",
    ")\n",
    "\n",
    "def currency_to_float(x):\n",
    "    return float(x.replace('$', '').replace(',', ''))\n",
    "\n",
    "def parse_marcus_bank_statements_by_year(bank, year, bank_statements_file_path):\n",
    "    \"\"\"\n",
    "    Go through a year of monthly bank statements for a given bank and parse\n",
    "    the statements and return a df.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(bank_statements_file_path, bank, year)\n",
    "    monthly_bank_statement_list = os.listdir(file_path)\n",
    "    monthly_bank_statement_list = [i for i in monthly_bank_statement_list if i != '.DS_Store']\n",
    "    transactions_df_list = []\n",
    "    for monthly_bank_statement_file in monthly_bank_statement_list:\n",
    "        month = monthly_bank_statement_file.split('_')[1].split('.')[0]\n",
    "        with open(os.path.join(file_path, monthly_bank_statement_file), \"rb\") as file:\n",
    "            pdf = pdftotext.PDF(file, physical=True)\n",
    "            if len(pdf) == 1:\n",
    "                first_page = pdf[0]\n",
    "                lines1 = first_page.split(\"\\n\")\n",
    "                lines1 = [i.lstrip() for i in lines1]\n",
    "                lines1 = [i for i in lines1 if i != '']\n",
    "                lines2 = None\n",
    "            elif len(pdf) == 2:\n",
    "                first_page = pdf[0]\n",
    "                lines1 = first_page.split(\"\\n\")\n",
    "                second_page = pdf[1]\n",
    "                lines2 = second_page.split(\"\\n\")\n",
    "\n",
    "                lines1 = [i.lstrip() for i in lines1]\n",
    "                lines1 = [i for i in lines1 if i != '']\n",
    "                lines2 = [i.lstrip() for i in lines2]\n",
    "                lines2 = [i for i in lines2 if i != '']\n",
    "            else:\n",
    "                pdf_length = len(pdf)\n",
    "                raise Exception(f'New length for pdf ({pdf_length}), time to set new rules. Info: {bank}, {year}, {month}')\n",
    "\n",
    "        if lines2 is None:\n",
    "            transactions_forward_list = lines1[lines1.index('ACCOUNT ACTIVITY'):]\n",
    "        else:\n",
    "            transactions_forward_list = lines1[lines1.index('ACCOUNT ACTIVITY'):] + lines2[lines2.index('ACCOUNT ACTIVITY (continued)'):]\n",
    "\n",
    "        transaction_lines_list = transactions_forward_list\n",
    "        transaction_lines_list = transaction_lines_list.copy()\n",
    "        beginning_balance_list = transaction_lines_list.copy()\n",
    "\n",
    "        # get the beginning entry for reference\n",
    "        beginning_balance_entry = [i for i in beginning_balance_list if 'Beginning Balance' in i][0]\n",
    "        beginning_balance_dict = re.search(\n",
    "            pattern=(\n",
    "                r\"(?P<transaction_date>\\d+/\\d+/\\d+)\\s*\"\n",
    "                r\"(?P<description>.*?)(?=\\$)\"\n",
    "                r\"(?P<balance>.*)\"\n",
    "            ),\n",
    "            string=beginning_balance_entry\n",
    "        ).groupdict()\n",
    "\n",
    "        # parse the other lines\n",
    "        date_pattern = r\"^\\d{2}/\\d{2}/\\d{4}\"\n",
    "        bad_idx_list = []\n",
    "        for idx, txc_line in enumerate(transaction_lines_list):\n",
    "            if not bool(re.match(date_pattern, txc_line[:10])):\n",
    "                bad_idx_list.append(idx)\n",
    "\n",
    "        transaction_lines_list = remove_indices(transaction_lines_list, bad_idx_list)\n",
    "        transaction_lines_list = [\n",
    "            i for i in transaction_lines_list if all(substring not in i for substring in ['Beginning Balance', 'Ending Balance'])\n",
    "        ]\n",
    "\n",
    "        transactions_df = parse_lines_with_regex(transaction_lines_list, transaction_pattern)\n",
    "        transactions_df['credit_debit'] = transactions_df['credit_debit'].apply(currency_to_float)\n",
    "        transactions_df['balance'] = transactions_df['balance'].apply(currency_to_float)\n",
    "        beginning_balance_df = pd.DataFrame([beginning_balance_dict])\n",
    "        beginning_balance_df['balance'] = beginning_balance_df['balance'].apply(currency_to_float)\n",
    "        transactions_df = pd.concat(\n",
    "            [\n",
    "                beginning_balance_df,\n",
    "                transactions_df\n",
    "            ]\n",
    "        )\n",
    "        transactions_df['description'] = transactions_df['description'].apply(lambda x: x.rstrip())\n",
    "\n",
    "        # for reversal charges which have negative values in the credit statement\n",
    "        transactions_df['credit_debit'] = abs(transactions_df['credit_debit'])\n",
    "\n",
    "        credit_debit_multiplier_list = []\n",
    "        transactions_df.reset_index(drop=True, inplace=True) # fix idx for the iterrows\n",
    "        for idx, row in transactions_df.iterrows():\n",
    "            cur_balance = row['balance']\n",
    "            if idx > 0:\n",
    "                if cur_balance > prev_balance:\n",
    "                    credit_debit_multiplier = 1\n",
    "                else:\n",
    "                    credit_debit_multiplier = -1\n",
    "            else:\n",
    "                credit_debit_multiplier = 1\n",
    "            credit_debit_multiplier_list.append(credit_debit_multiplier)\n",
    "            prev_balance = row['balance']\n",
    "\n",
    "        transactions_df['credit_debit_multiplier'] = credit_debit_multiplier_list\n",
    "        transactions_df['credit_debit'] = transactions_df['credit_debit'] * transactions_df['credit_debit_multiplier']\n",
    "        transactions_df.drop(['credit_debit_multiplier'], axis=1, inplace=True)\n",
    "        transactions_df = transactions_df.iloc[1:,:].copy() # drop the Beginning Balance\n",
    "        transactions_df.sort_values(by='transaction_date', ascending=True, inplace=True)\n",
    "        transactions_df_list.append(transactions_df)\n",
    "\n",
    "    return pd.concat(transactions_df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to delete the extra pages in the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'credit_debit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(ref_df[year][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m approx_sum(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcredit_debit\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m tmp \u001b[38;5;241m==\u001b[39m ref_df[year][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m transactions_2021_df \u001b[38;5;241m=\u001b[39m \u001b[43mparse_marcus_bank_statements_by_year\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmarcus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2021\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbank_statements_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBANK_STATEMENTS_FILE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m transactions_2022_df \u001b[38;5;241m=\u001b[39m parse_marcus_bank_statements_by_year(\n\u001b[1;32m     21\u001b[0m     bank\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarcus\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m     year\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m     bank_statements_file_path\u001b[38;5;241m=\u001b[39mBANK_STATEMENTS_FILE_PATH,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m transactions_2023_df \u001b[38;5;241m=\u001b[39m parse_marcus_bank_statements_by_year(\n\u001b[1;32m     26\u001b[0m     bank\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarcus\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m     year\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m     bank_statements_file_path\u001b[38;5;241m=\u001b[39mBANK_STATEMENTS_FILE_PATH,\n\u001b[1;32m     29\u001b[0m )\n",
      "Cell \u001b[0;32mIn[87], line 87\u001b[0m, in \u001b[0;36mparse_marcus_bank_statements_by_year\u001b[0;34m(bank, year, bank_statements_file_path)\u001b[0m\n\u001b[1;32m     82\u001b[0m transaction_lines_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     83\u001b[0m     i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m transaction_lines_list \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(substring \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m substring \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeginning Balance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnding Balance\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     84\u001b[0m ]\n\u001b[1;32m     86\u001b[0m transactions_df \u001b[38;5;241m=\u001b[39m parse_lines_with_regex(transaction_lines_list, transaction_pattern)\n\u001b[0;32m---> 87\u001b[0m transactions_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcredit_debit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtransactions_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcredit_debit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(currency_to_float)\n\u001b[1;32m     88\u001b[0m transactions_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transactions_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(currency_to_float)\n\u001b[1;32m     89\u001b[0m beginning_balance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([beginning_balance_dict])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance_tracker_app/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance_tracker_app/lib/python3.11/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'credit_debit'"
     ]
    }
   ],
   "source": [
    "marcus_annual_beginning_ending_balance_df = pd.DataFrame({\n",
    "    '2021': [0, 11719.53],\n",
    "    '2022': [11719.53, 4877.32],\n",
    "    '2023': [4877.32, 28770.03],\n",
    "    '2024': [28770.03, 30478.36],\n",
    "})\n",
    "\n",
    "def approx_sum(x):\n",
    "    return round(sum(x), 2)\n",
    "\n",
    "def test_annual_balance_marcus(df, year, ref_df):\n",
    "    tmp = round(ref_df[year][0] + approx_sum(df['credit_debit']), 2)\n",
    "    assert tmp == ref_df[year][1]\n",
    "\n",
    "transactions_2021_df = parse_marcus_bank_statements_by_year(\n",
    "    bank='marcus',\n",
    "    year='2021',\n",
    "    bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2022_df = parse_marcus_bank_statements_by_year(\n",
    "    bank='marcus',\n",
    "    year='2022',\n",
    "    bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2023_df = parse_marcus_bank_statements_by_year(\n",
    "    bank='marcus',\n",
    "    year='2023',\n",
    "    bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2024_df = parse_marcus_bank_statements_by_year(\n",
    "    bank='marcus',\n",
    "    year='2024',\n",
    "    bank_statements_file_path=BANK_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "\n",
    "# test for regressions\n",
    "test_annual_balance_marcus(\n",
    "    df=transactions_2021_df,\n",
    "    year='2021',\n",
    "    ref_df=marcus_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_marcus(\n",
    "    df=transactions_2022_df,\n",
    "    year='2022',\n",
    "    ref_df=marcus_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_marcus(\n",
    "    df=transactions_2023_df,\n",
    "    year='2023',\n",
    "    ref_df=marcus_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_marcus(\n",
    "    df=transactions_2024_df,\n",
    "    year='2024',\n",
    "    ref_df=marcus_annual_beginning_ending_balance_df\n",
    ")\n",
    "\n",
    "transactions_df = pd.concat([\n",
    "    transactions_2021_df,\n",
    "    transactions_2022_df,\n",
    "    transactions_2023_df,\n",
    "    transactions_2024_df,\n",
    "])\n",
    "\n",
    "transactions_df['transaction_date'] = pd.to_datetime(transactions_df['transaction_date'])\n",
    "transactions_df.sort_values(by='transaction_date', ascending=True, inplace=True)\n",
    "transactions_df.reset_index(drop=True, inplace=True)\n",
    "transactions_df['transaction_date'] = transactions_df['transaction_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_category_mapping = {\n",
    "    'ACH Deposit': 'Deposit',\n",
    "    'ACH Withdrawal': 'Withdrawal',\n",
    "    'Interest Paid': 'Interest',\n",
    "    'SAV Decrease Int Paid': 'Interest',\n",
    "    'SAV Increase Int Paid': 'Interest',\n",
    "}\n",
    "\n",
    "\n",
    "for k, v in description_category_mapping.items():\n",
    "    transactions_df.loc[\n",
    "        transactions_df['description'].str.contains(k),\n",
    "        'category'\n",
    "    ] = v\n",
    "\n",
    "transactions_df.loc[transactions_df['category'].isna(), 'category'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1CAyyf2kr-pS7LNX1a_0ithw6niL3Js3K4ZEOlwDViZY',\n",
       " 'replies': [{}]}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = gspread.service_account()\n",
    "finance_tracker_db_spreadsheet = gc.open_by_key(SPREADSHEET_KEY)\n",
    "marcus_worksheet = finance_tracker_db_spreadsheet.worksheet('marcus_bank_statements')\n",
    "marcus_worksheet.update([transactions_df.columns.values.tolist()] + transactions_df.values.tolist())\n",
    "marcus_worksheet.format(\"C:D\", {\"numberFormat\": {\"type\": \"CURRENCY\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# East West Bank Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lines_with_regex(lines, transaction_pattern):\n",
    "    # Ref.: https://levelup.gitconnected.com/creating-a-bank-statement-parser-with-python-9223b895ebae\n",
    "    transactions = []\n",
    "    for line in lines:\n",
    "        match = re.search(pattern=transaction_pattern, string=line)\n",
    "        if match:\n",
    "            transactions.append(match.groupdict())\n",
    "\n",
    "    return pd.DataFrame(transactions)\n",
    "\n",
    "transaction_pattern = (\n",
    "    r\"(?P<post_date>\\d{2}/\\d{2})\\s*\"\n",
    "    r\"(?P<transaction_date>\\d{2}/\\d{2})\\s*\"\n",
    "    r\"(?P<ref_num>\\S*)\\s*\"\n",
    "    r\"(?P<description>.*?)(?=\\$)\"\n",
    "    r\"(?P<amount>\\S.*)\"\n",
    ")\n",
    "\n",
    "def clean_amount_col(x):\n",
    "    # remove ($), (,), (alphabetical)\n",
    "    return float(re.sub(r\"[^\\d|\\.]\", \"\", x.replace('$', '')))\n",
    "\n",
    "def check_list_len_bool(l):\n",
    "    if len(l) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def remove_indices(lst, indices):\n",
    "    # Sort indices in descending order to avoid reindexing issues\n",
    "    indices = sorted(indices, reverse=True)\n",
    "    \n",
    "    # Remove elements at each index\n",
    "    for index in indices:\n",
    "        if 0 <= index < len(lst):\n",
    "            lst.pop(index)\n",
    "        else:\n",
    "            raise IndexError(f\"Index {index} is out of bounds for list of length {len(lst)}\")\n",
    "    \n",
    "    return lst\n",
    "\n",
    "def drop_multiline_transactions(transaction_lines):\n",
    "    transaction_lines = transaction_lines.copy()\n",
    "    bad_idx_list = []\n",
    "    for idx, i in enumerate(transaction_lines):\n",
    "        # if not bool(re.match(r\"^(\\d{2}/\\d{2})\\s*(\\d{2}/\\d{2})\", i)):\n",
    "        if not bool(re.match(r\"^(\\d{2}/\\d{2})\\s*\", i)):\n",
    "            bad_idx_list.append(idx)\n",
    "    transaction_lines = remove_indices(lst=transaction_lines, indices=bad_idx_list)\n",
    "    return transaction_lines\n",
    "\n",
    "def insert_na_for_missing_txn_date_and_ref_num(transaction_lines):\n",
    "    # works only for when there's a post date and no transaction date\n",
    "    null_idx_list = []\n",
    "    for idx, i in enumerate(transaction_lines):\n",
    "        if bool(re.match(r\"^(\\d{2}/\\d{2})\\s{8,}\", i)):\n",
    "            null_idx_list.append(idx)\n",
    "\n",
    "    for idx in null_idx_list:\n",
    "        transaction_lines[idx] = transaction_lines[idx][:8] + \\\n",
    "            transaction_lines[idx][:5] + \\\n",
    "            '    NA' + \\\n",
    "            transaction_lines[idx][10:]\n",
    "    return transaction_lines\n",
    "\n",
    "def process_transaction_lines(\n",
    "    payments_and_other_credits_lines=[],\n",
    "    purchases_and_other_debits_lines=[],\n",
    "    fees_lines=[],\n",
    "    interest_charged_lines=[],\n",
    "):\n",
    "    \"\"\"\n",
    "    Return the transactions df from the transaction lines.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        payments_and_other_credits_lines = drop_multiline_transactions(payments_and_other_credits_lines)\n",
    "        payments_and_other_credits_lines = insert_na_for_missing_txn_date_and_ref_num(payments_and_other_credits_lines)\n",
    "        payments_and_other_credits_df = parse_lines_with_regex(payments_and_other_credits_lines, transaction_pattern)\n",
    "        payments_and_other_credits_df['amount'] = payments_and_other_credits_df['amount'].apply(clean_amount_col)\n",
    "        payments_and_other_credits_df['amount'] = payments_and_other_credits_df['amount'] * -1 # make negative\n",
    "    except:\n",
    "        payments_and_other_credits_df = pd.DataFrame([])\n",
    "    try:\n",
    "        purchases_and_other_debits_lines = drop_multiline_transactions(purchases_and_other_debits_lines)\n",
    "        purchases_and_other_debits_lines = insert_na_for_missing_txn_date_and_ref_num(purchases_and_other_debits_lines)\n",
    "        purchases_and_other_debits_df = parse_lines_with_regex(purchases_and_other_debits_lines, transaction_pattern)\n",
    "        purchases_and_other_debits_df['amount'] = purchases_and_other_debits_df['amount'].apply(clean_amount_col)\n",
    "    except:\n",
    "        purchases_and_other_debits_df = pd.DataFrame([])\n",
    "    try:\n",
    "        fees_lines = drop_multiline_transactions(fees_lines)\n",
    "        fees_lines = insert_na_for_missing_txn_date_and_ref_num(fees_lines)\n",
    "        fees_df = parse_lines_with_regex(fees_lines, transaction_pattern)\n",
    "        fees_df['amount'] = fees_df['amount'].apply(clean_amount_col)\n",
    "    except:\n",
    "        fees_lines_df = pd.DataFrame([])\n",
    "    try:\n",
    "        interest_charged_lines = drop_multiline_transactions(interest_charged_lines)\n",
    "        interest_charged_lines = insert_na_for_missing_txn_date_and_ref_num(interest_charged_lines)\n",
    "        interest_charged_df = parse_lines_with_regex(interest_charged_lines, transaction_pattern)\n",
    "        interest_charged_df['amount'] = interest_charged_df['amount'].apply(clean_amount_col)\n",
    "    except:\n",
    "        interest_charged_df = pd.DataFrame([])\n",
    "\n",
    "    transactions_df = pd.concat([\n",
    "        payments_and_other_credits_df,\n",
    "        purchases_and_other_debits_df,\n",
    "        fees_df,\n",
    "        interest_charged_df,\n",
    "    ])\n",
    "    transactions_df.drop(['ref_num'], axis=1, inplace=True)\n",
    "    return transactions_df\n",
    "\n",
    "def add_year_to_date(first_page, transactions_df):\n",
    "    \"\"\"\n",
    "    Add the year to the date columns. Handle cases with two years (Jan/Dec).\n",
    "    \"\"\"\n",
    "    date_range = first_page.split(\"\\n\")[0].split('Statement')[1].split('Page')[0].lstrip().rstrip()\n",
    "    start_date = date_range.split(' - ')[0]\n",
    "    end_date = date_range.split(' - ')[1]\n",
    "    start_year = start_date[6:]\n",
    "    start_month = start_date[:2]\n",
    "    end_year = end_date[6:]\n",
    "    end_month = end_date[:2]\n",
    "    if start_year == end_year:\n",
    "        transactions_df['post_date'] = transactions_df['post_date'] + '/' + start_year\n",
    "        transactions_df['transaction_date'] = transactions_df['transaction_date'] + '/' + start_year\n",
    "    else:\n",
    "        month_year_mapping = {\n",
    "            start_month: start_year,\n",
    "            end_month: end_year,\n",
    "        }\n",
    "        transactions_df['post_date_month'] = transactions_df['post_date'].apply(lambda x: x.split('/')[0])\n",
    "        transactions_df['transaction_date_month'] = transactions_df['transaction_date'].apply(lambda x: x.split('/')[0])\n",
    "        transactions_df['post_date'] = transactions_df['post_date'] + \\\n",
    "            '/' + \\\n",
    "            transactions_df['post_date_month'].apply(lambda x: month_year_mapping[x])\n",
    "        transactions_df['transaction_date'] = transactions_df['transaction_date'] + \\\n",
    "            '/' + \\\n",
    "            transactions_df['transaction_date_month'].apply(lambda x: month_year_mapping[x])\n",
    "        transactions_df.drop(['post_date_month', 'transaction_date_month'], axis=1, inplace=True)\n",
    "\n",
    "    transactions_df['date_range'] = date_range\n",
    "    return transactions_df\n",
    "\n",
    "def check_for_indices(lines, keyword, exact_match=True):\n",
    "    idx_list = []\n",
    "    for idx, i in enumerate(lines):\n",
    "        if exact_match:\n",
    "            if i == keyword:\n",
    "                idx_list.append(idx)\n",
    "        else:\n",
    "            if i[:len(keyword)] == keyword:\n",
    "                idx_list.append(idx)\n",
    "    return idx_list\n",
    "\n",
    "def parse_east_west_bank_credit_card_statements_by_year(credit_card, year, credit_card_statements_file_path):\n",
    "    \"\"\"\n",
    "    Go through a year of monthly bank statements for a given bank and parse\n",
    "    the statements and return a df.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(credit_card_statements_file_path, credit_card, year)\n",
    "    monthly_credit_card_statement_list = os.listdir(file_path)\n",
    "    monthly_credit_card_statement_list = [i for i in monthly_credit_card_statement_list if i != '.DS_Store']\n",
    "    transactions_df_list = []\n",
    "    for monthly_credit_card_statement_file in monthly_credit_card_statement_list:\n",
    "        month = monthly_credit_card_statement_file.split('_')[1].split('.')[0]\n",
    "        with open(os.path.join(file_path, monthly_credit_card_statement_file), \"rb\") as file:\n",
    "            pdf = pdftotext.PDF(file, physical=True)\n",
    "\n",
    "        # collect lines\n",
    "        lines_list = []\n",
    "        for page in pdf:\n",
    "            lines = page.split(\"\\n\")\n",
    "            lines = [i.lstrip() for i in lines]\n",
    "            lines = [i for i in lines if i != '']\n",
    "            if [i for i in lines if 'Transactions' in i]:\n",
    "                lines_list += lines\n",
    "\n",
    "        payments_and_other_credits_start_idx_list = check_for_indices(lines_list, 'Payments and Other Credits')\n",
    "        purchases_and_other_debits_start_idx_list = check_for_indices(lines_list, 'Purchases and Other Debits')\n",
    "        total_this_period_idx_list = check_for_indices(lines_list, 'TOTAL THIS PERIOD', False)\n",
    "        fees_start_idx_list = check_for_indices(lines_list, 'Fees')\n",
    "        total_fees_this_period_idx_list = check_for_indices(lines_list, 'TOTAL FEES THIS PERIOD', False)\n",
    "        interest_charged_start_idx_list = check_for_indices(lines_list, 'Interest Charged')\n",
    "        interest_charged_idx_list = check_for_indices(lines_list, 'TOTAL INTEREST THIS PERIOD', False)\n",
    "        if payments_and_other_credits_start_idx_list:\n",
    "            payments_and_other_credits_lines = lines_list[\n",
    "                payments_and_other_credits_start_idx_list[0] + 3: \\\n",
    "                total_this_period_idx_list[0]\n",
    "            ]\n",
    "        else:\n",
    "            payments_and_other_credits_lines = []\n",
    "        if purchases_and_other_debits_start_idx_list:\n",
    "            purchases_and_other_debits_lines = lines_list[\n",
    "                purchases_and_other_debits_start_idx_list[0] + 3: \\\n",
    "                total_this_period_idx_list[-1]\n",
    "            ]\n",
    "        else:\n",
    "            purchases_and_other_debits_lines = []\n",
    "        if fees_start_idx_list:\n",
    "            fees_lines = lines_list[\n",
    "                fees_start_idx_list[0] + 3: \\\n",
    "                total_fees_this_period_idx_list[0]\n",
    "            ]\n",
    "        else:\n",
    "            fees_lines = []\n",
    "        if interest_charged_start_idx_list:\n",
    "            interest_charged_lines = lines_list[\n",
    "                interest_charged_start_idx_list[0] + 3: \\\n",
    "                interest_charged_idx_list[0]\n",
    "            ]\n",
    "        else:\n",
    "            interest_charged_lines = []\n",
    "\n",
    "        transactions_df = process_transaction_lines(\n",
    "            payments_and_other_credits_lines,\n",
    "            purchases_and_other_debits_lines,\n",
    "            fees_lines,\n",
    "            interest_charged_lines,\n",
    "        )\n",
    "        transactions_df = add_year_to_date(pdf[2], transactions_df)\n",
    "        transactions_df_list.append(transactions_df)\n",
    "    return pd.concat(transactions_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "east_west_bank_credit_card_annual_beginning_ending_balance_df = pd.DataFrame({\n",
    "    '2017': [1937.56, 1748.56],\n",
    "    '2018': [1748.56, 1790.84],\n",
    "    '2019': [1790.84, 45.21],\n",
    "    '2020': [45.21, 1080.03],\n",
    "    '2021': [1080.03, 99.31],\n",
    "    '2022': [99.31, 137.52],\n",
    "    '2023': [137.52, 82.56],\n",
    "    '2024': [82.56, -275.03],\n",
    "})\n",
    "\n",
    "transactions_2017_df = parse_east_west_bank_credit_card_statements_by_year(\n",
    "    credit_card='east_west_bank',\n",
    "    year='2017',\n",
    "    credit_card_statements_file_path=CREDIT_CARD_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2018_df = parse_east_west_bank_credit_card_statements_by_year(\n",
    "    credit_card='east_west_bank',\n",
    "    year='2018',\n",
    "    credit_card_statements_file_path=CREDIT_CARD_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2019_df = parse_east_west_bank_credit_card_statements_by_year(\n",
    "    credit_card='east_west_bank',\n",
    "    year='2019',\n",
    "    credit_card_statements_file_path=CREDIT_CARD_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2020_df = parse_east_west_bank_credit_card_statements_by_year(\n",
    "    credit_card='east_west_bank',\n",
    "    year='2020',\n",
    "    credit_card_statements_file_path=CREDIT_CARD_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2021_df = parse_east_west_bank_credit_card_statements_by_year(\n",
    "    credit_card='east_west_bank',\n",
    "    year='2021',\n",
    "    credit_card_statements_file_path=CREDIT_CARD_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2022_df = parse_east_west_bank_credit_card_statements_by_year(\n",
    "    credit_card='east_west_bank',\n",
    "    year='2022',\n",
    "    credit_card_statements_file_path=CREDIT_CARD_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2023_df = parse_east_west_bank_credit_card_statements_by_year(\n",
    "    credit_card='east_west_bank',\n",
    "    year='2023',\n",
    "    credit_card_statements_file_path=CREDIT_CARD_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "transactions_2024_df = parse_east_west_bank_credit_card_statements_by_year(\n",
    "    credit_card='east_west_bank',\n",
    "    year='2024',\n",
    "    credit_card_statements_file_path=CREDIT_CARD_STATEMENTS_FILE_PATH,\n",
    ")\n",
    "\n",
    "def approx_sum(x):\n",
    "    return round(sum(x), 2)\n",
    "\n",
    "def test_annual_balance_east_west_bank_credit_card(df, year, ref_df):\n",
    "    tmp = round(ref_df[year][0] + approx_sum(df['amount']), 2)\n",
    "    assert tmp == ref_df[year][1]\n",
    "\n",
    "# test for regressions\n",
    "test_annual_balance_east_west_bank_credit_card(\n",
    "    df=transactions_2017_df,\n",
    "    year='2017',\n",
    "    ref_df=east_west_bank_credit_card_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank_credit_card(\n",
    "    df=transactions_2018_df,\n",
    "    year='2018',\n",
    "    ref_df=east_west_bank_credit_card_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank_credit_card(\n",
    "    df=transactions_2019_df,\n",
    "    year='2019',\n",
    "    ref_df=east_west_bank_credit_card_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank_credit_card(\n",
    "    df=transactions_2020_df,\n",
    "    year='2020',\n",
    "    ref_df=east_west_bank_credit_card_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank_credit_card(\n",
    "    df=transactions_2021_df,\n",
    "    year='2021',\n",
    "    ref_df=east_west_bank_credit_card_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank_credit_card(\n",
    "    df=transactions_2022_df,\n",
    "    year='2022',\n",
    "    ref_df=east_west_bank_credit_card_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank_credit_card(\n",
    "    df=transactions_2023_df,\n",
    "    year='2023',\n",
    "    ref_df=east_west_bank_credit_card_annual_beginning_ending_balance_df\n",
    ")\n",
    "test_annual_balance_east_west_bank_credit_card(\n",
    "    df=transactions_2024_df,\n",
    "    year='2024',\n",
    "    ref_df=east_west_bank_credit_card_annual_beginning_ending_balance_df\n",
    ")\n",
    "\n",
    "total_transactions_df = pd.concat([\n",
    "    transactions_2017_df,\n",
    "    transactions_2018_df,\n",
    "    transactions_2019_df,\n",
    "    transactions_2020_df,\n",
    "    transactions_2021_df,\n",
    "    transactions_2022_df,\n",
    "    transactions_2023_df,\n",
    "    transactions_2024_df\n",
    "])\n",
    "\n",
    "total_transactions_df['post_date_fmt'] = pd.to_datetime(total_transactions_df['post_date'])\n",
    "total_transactions_df['transaction_date_fmt'] = pd.to_datetime(total_transactions_df['transaction_date'])\n",
    "total_transactions_df.sort_values(\n",
    "    by=['post_date_fmt', 'transaction_date_fmt', 'amount', 'description'],\n",
    "    ascending=[True, True, True, True],\n",
    "    inplace=True\n",
    ")\n",
    "total_transactions_df.drop(['post_date_fmt', 'transaction_date_fmt'], axis=1, inplace=True)\n",
    "total_transactions_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_category_mapping = {\n",
    "    'WAL-MART': 'Groceries',\n",
    "    'WALMART': 'Groceries',\n",
    "    'COSTCO WHSE': 'Groceries',\n",
    "    '99 RANCH': 'Groceries',\n",
    "    \"KIM'S MART\": 'Groceries',\n",
    "    'ALBERTSONS': 'Groceries',\n",
    "    'SAFEWAY': 'Groceries',\n",
    "    'MANNA ORIENTAL': 'Groceries',\n",
    "    'LUCKY ': 'Groceries',\n",
    "    'MARINA FOOD': 'Groceries',\n",
    "    'SPIRIT MARKET': 'Groceries',\n",
    "    'WESTLAKE IGA MARKE': 'Groceries',\n",
    "    'FOOD 4 LESS': 'Groceries',\n",
    "    'SMART AND FINAL': 'Groceries',\n",
    "    \"TRADER JOE'S\": 'Groceries',\n",
    "    'OSAKA MARKET': 'Groceries',\n",
    "    'DUFFL': 'Groceries',\n",
    "    '7-ELEVEN': 'Groceries',\n",
    "    'WHOLEFDS': 'Groceries',\n",
    "    'KROGER': 'Groceries',\n",
    "    'HANKOOK': 'Groceries',\n",
    "    'Prime Video': 'Amazon',\n",
    "    'AMZN': 'Amazon',\n",
    "    'AmazonPckupCampusLckr': 'Amazon',\n",
    "    'Amazon': 'Amazon',\n",
    "    'aliexpress': 'E-commerce',\n",
    "    'GEARBEST': 'E-commerce',\n",
    "    'TARGET': 'Target',\n",
    "    'CVS': 'CVS',\n",
    "    'BEST BUY': 'Best Buy',\n",
    "    'BESTBUY': 'Best Buy',\n",
    "    'VENMO': 'Venmo',\n",
    "    'PAYPAL': 'PayPal',\n",
    "    '76 - ': 'Gas',\n",
    "    'COSTCO GAS': 'Gas',\n",
    "    'SHELL OIL': 'Gas',\n",
    "    'CHEVRON': 'Gas',\n",
    "    'ROTTEN ROBBIE': 'Gas',\n",
    "    'EXXONMOBIL': 'Gas',\n",
    "    'CONSERV FUEL': 'Gas',\n",
    "    'SAN PASO TRUCK STOP': 'Gas',\n",
    "    'FUEL DEPOT': 'Gas',\n",
    "    'VALERO': 'Gas',\n",
    "    'BEL AIR': 'Gas',\n",
    "    'PARKING': 'Parking',\n",
    "    'UCD TAPS': 'Parking',\n",
    "    'UCSB TPS': 'Parking',\n",
    "    'MTA METER': 'Parking',\n",
    "    'PARKMOBILE': 'Parking',\n",
    "    'CHIPOTLE': 'Restaurant',\n",
    "    'PHO KING 4': 'Restaurant',\n",
    "    'PHO MAI': 'Restaurant',\n",
    "    'SUBWAY': 'Restaurant',\n",
    "    'HUB MARKET': 'Restaurant',\n",
    "    'UCD SOUTH SILO': 'Restaurant',\n",
    "    'MCDONALD': 'Restaurant',\n",
    "    'Taqueria': 'Restaurant',\n",
    "    'STARBUCKS': 'Restaurant',\n",
    "    'SUJU': 'Restaurant',\n",
    "    'SLAP FACE': 'Restaurant',\n",
    "    'TACOS': 'Restaurant',\n",
    "    'CMSVEND': 'Restaurant',\n",
    "    'SWEETHONEY': 'Restaurant',\n",
    "    'TEASPOON': 'Restaurant',\n",
    "    'JOE THE JUICE': 'Restaurant',\n",
    "    'SWEETFIN': 'Restaurant',\n",
    "    'TEXAS RDHSE': 'Restaurant',\n",
    "    'YOSHINOYA': 'Restaurant',\n",
    "    'HUNGRYPANDA': 'Restaurant',\n",
    "    'Nikka Ramen': 'Restaurant',\n",
    "    'EINSTEINMOBILEAPP': 'Restaurant',\n",
    "    'COLDSTONE': 'Restaurant',\n",
    "    'BUFFALO WILD WINGS': 'Restaurant',\n",
    "    'BUFFET': 'Restaurant',\n",
    "    \"PING'S BISTRO\": 'Restaurant',\n",
    "    'SUSHI': 'Restaurant',\n",
    "    \"OPPI'Z\": 'Restaurant',\n",
    "    \"McDonald's\": 'Restaurant',\n",
    "    'RESTAURANT': 'Restaurant',\n",
    "    'DINER': 'Restaurant',\n",
    "    'UNA MAS': 'Restaurant',\n",
    "    'CANTEEN VENDING': 'Restaurant', \n",
    "    'SWEET AND SHAVE': 'Restaurant',\n",
    "    'ABERDEEN CAFE': 'Restaurant',\n",
    "    \"RAJA'S TANDOOR\": 'Restaurant',\n",
    "    \"DOMINO'S\": 'Restaurant',\n",
    "    'CAFE': 'Restaurant',\n",
    "    'THE HABIT': 'Restaurant',\n",
    "    'THE SHOP CAFE': 'Restaurant',\n",
    "    'PEETS COFFEE': 'Restaurant',\n",
    "    'BLAZE PIZZA': 'Restaurant',\n",
    "    'DUTCHBROSCO': 'Restaurant',\n",
    "    'THE LUNCH BOX': 'Restaurant',\n",
    "    'THE GURKHA KITCHEN': 'Restaurant',\n",
    "    'RESTAURA': 'Restaurant',\n",
    "    'LANZHOU': 'Restaurant',\n",
    "    'GEN KOREAN BBQ': 'Restaurant',\n",
    "    'Barbareno': 'Restaurant',\n",
    "    'FASTRAK': 'Government',\n",
    "    'DMV': 'Government',\n",
    "    'KAISER': 'Kaiser',\n",
    "    'APPLE.COM/BILL': 'Recurring Payments',\n",
    "    'KAISER PAY': 'Recurring Payments',\n",
    "    'Audible': 'Recurring Payments',\n",
    "    'LASTPASS': 'Recurring Payments',\n",
    "    'ITUNES.COM/BILL': 'Recurring Payments',\n",
    "    'PROACTIV': 'Recurring Payments',\n",
    "    'AAA INSURANCE': 'Recurring Payments',\n",
    "    'ELLIOTT WAVE': 'Trading',\n",
    "    'TRADE IDEAS': 'Trading',\n",
    "    '4X SOLUTIONS': 'Trading',\n",
    "    'LIVETRADERS': 'Trading',\n",
    "    'SIERRA CHART': 'Trading',\n",
    "    'G7FX': 'Trading',\n",
    "    'WASH LAUNDRY': 'Laundry',\n",
    "    'HOSTEL WORLD': 'Travel',\n",
    "    ' HK ': 'Travel',\n",
    "    'HONG KO': 'Travel',\n",
    "    'ISQUARE': 'Travel',\n",
    "    'JASONS': 'Travel',\n",
    "    \"WATSON'S\": 'Travel',\n",
    "    ' HO': 'Travel',\n",
    "    'MANNINGS': 'Travel',\n",
    "    'FRGN TRANS FEE-': 'Travel',\n",
    "    'BEIJING CN': 'Travel',\n",
    "    'BEIJING': 'Travel',\n",
    "    'SHENZHEN CN': 'Travel',\n",
    "    'SUP TAHOE': 'Travel',\n",
    "    'AIRBNB': 'Travel',\n",
    "    'DOLE PLANTATION': 'Travel',\n",
    "    'OAHU': 'Travel',\n",
    "    'HEARST CASTLE': 'Travel',\n",
    "    'ISLAND PACKERS': 'Travel',\n",
    "    'TURO': 'Travel',\n",
    "    'FOX THEATRE': 'Travel',\n",
    "    'TICKETSATWORK': 'Travel',\n",
    "    'AIR CAN': 'Airplane Tickets',\n",
    "    'UNITED ': 'Airplane Tickets',\n",
    "    'AIR TRANS': 'Airplane Tickets',\n",
    "    'SPIRIT': 'Airplane Tickets',\n",
    "    'CITY COLLEGE': 'Education',\n",
    "    'CCSF': 'Education',\n",
    "    'OHLONE': 'Education',\n",
    "    'COLLEGE': 'Education',\n",
    "    'UCD': 'Education',\n",
    "    'UDEMY': 'Education',\n",
    "    'CHEGG': 'Education',\n",
    "    'DATACAMP': 'Education',\n",
    "    'COURSERA': 'Education',\n",
    "    'MEMRISECOM': 'Education',\n",
    "    'GRAMMARLY': 'Education',\n",
    "    'CHINESE ZERO': 'Education',\n",
    "    'KAPLAN': 'Education',\n",
    "    'WYZANT': 'Education',\n",
    "    'AMC': 'Movies',\n",
    "    'adidas': 'Clothes',\n",
    "    \"VICTORIA'S SECRET\": 'Clothes',\n",
    "    'MACY': 'Clothes',\n",
    "    'EXPRESS': 'Clothes',\n",
    "    'SAKS': 'Clothes',\n",
    "    'TANDY LEATHER': 'Clothes',\n",
    "    'ADIDAS': 'Clothes',\n",
    "    \"LEVI'S OUTLET\": 'Clothes',\n",
    "    'DOCKERS': 'Clothes',\n",
    "    'FITNESS': 'Fitness',\n",
    "    'BADMINTON': 'Fitness',\n",
    "    'UCSB RECREATION': 'Fitness',\n",
    "    'luxiaojunbarbell': 'Fitness',\n",
    "    'BALLROOM CONNECTION': 'Fitness',\n",
    "    'PAYMENT': 'CC Payment',\n",
    "    'PAYMENT THANK': 'CC Payment',\n",
    "    'PAYMENT THANK YOU': 'CC Payment',\n",
    "    'PAYMENT THANK YOU': 'CC Payment',\n",
    "    'POINTS REDEEMED': 'Credit Card',\n",
    "    'ANNUAL MEMBERSHIP FEE': 'Credit Card',\n",
    "    'CREDIT ADJUSTMENT': 'Credit Card',\n",
    "    'ONLINE SPEND PROMOTION': 'Credit Card',\n",
    "}\n",
    "\n",
    "\n",
    "for k, v in description_category_mapping.items():\n",
    "    total_transactions_df.loc[\n",
    "        total_transactions_df['description'].str.contains(k),\n",
    "        'category'\n",
    "    ] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('max_colwidth', 1000)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "# total_transactions_df.style.set_properties(subset=['text'], **{'width': '1000px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_transactions_df.loc[total_transactions_df['category'].isna(), 'category'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Airplane Tickets        3865.73\n",
       "Amazon                  7933.23\n",
       "Best Buy                1382.45\n",
       "CC Payment           -118568.32\n",
       "Clothes                  937.54\n",
       "Credit Card            -1110.04\n",
       "E-commerce               319.54\n",
       "Education               6073.84\n",
       "Fitness                 1198.28\n",
       "Gas                     4778.37\n",
       "Government               946.00\n",
       "Groceries               8507.37\n",
       "Kaiser                  3732.68\n",
       "Laundry                  245.00\n",
       "Movies                    14.74\n",
       "Other                  14368.73\n",
       "Parking                  712.85\n",
       "PayPal                  1023.94\n",
       "Recurring Payments     20467.04\n",
       "Restaurant              2245.80\n",
       "Target                   189.80\n",
       "Trading                 9564.92\n",
       "Travel                  3377.76\n",
       "Venmo                  25580.16\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_transactions_df.groupby(['category'])['amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>EIG*BLUEHOST.COM   888-4014678 UT</td>\n",
       "      <td>-395.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>GLANBIA PERFORMANCE AURORA                     IL</td>\n",
       "      <td>-33.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>5401      PROV CR Groupon, Inc.       312-28864</td>\n",
       "      <td>-33.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>GUM.CO/CC* CURTIS EINS HTTPSGUMROAD. CA</td>\n",
       "      <td>-30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>FH* BLUE PLANET ADVENT WWW.BLUEPLANE CO</td>\n",
       "      <td>-26.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>UQ MILPITAS US0048 MILPITAS                CA</td>\n",
       "      <td>-22.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>ERENTERPLAN1889 INSURA 888-205-8118 TX</td>\n",
       "      <td>-0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>USPS PO 0585860456 WOODLAND CA</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>THE UPS STORE 0533 WOODLAND CA</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>PCCD - MERRITT       OAKLAND     CA</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>POP ID          CANOGA PARK CA</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>THE UPS STORE 0533 WOODLAND CA</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>T4 CJ         OAKLAND         CA</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>WM SUPERCENTER #5606 WOODLAND CA</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>WM SUPERCENTER #5606 WOODLAND CA</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>RITE AID STORE - 6048 DAVIS     CA</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>GOOGLE *YouTube Videos g.co/helppay# CA</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>GOOGLE *YouTube Videos g.co/helppay# CA</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>GOOGLE *YouTube Videos g.co/helppay# CA</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>GOOGLE *YouTube Videos g.co/helppay# CA</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>BAY STREET GARAGE         EMERYVILLE CA</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>ALAMEDACOCLERKRECORDER 801-9994323 UT</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>LION FOOD CENTER        NEWARK     CA</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>RITE AID STORE - 6048 DAVIS     CA</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>MATHPIX, INC.       9172976199 NY</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>MATHPIX, INC.     MATHPIX.COM NY</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>GOOGLE* YouTube Videos 650-2530000 CA</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>GOOGLE *YouTube Videos g.co/helppay# CA</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>MUNIMOBILE-SFMTA       415-701-2311 TX</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>MUNIMOBILE-SFMTA      415-701-2311 TX</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>COUNTY OF LA BEACHES &amp; MARINA DEL RE CA</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>WALGREENS #4107       WOODLAND CA</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>RITE AID STORE - 6048 DAVIS       CA</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>POSH BAGEL         DAVIS        CA</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>TACO BELL 30771        SAN RAMON CA</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>INDO CHINA MARKET    GOLETA      CA</td>\n",
       "      <td>5.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>DENNY'S #7888       FREMONT      CA</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>GONG CHA - FREMONT COR FREMONT           CA</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>GONG CHA - FREMONT COR FREMONT             CA</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>ARIA PRINTING AND SHIP FREMONT        CA</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>RITE AID STORE - 6048 DAVIS       CA</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>LION FOOD CENTER     MILPITAS CA</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>RITE AID STORE - 6048 DAVIS       CA</td>\n",
       "      <td>5.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>H MART - SAN JOSE   SAN JOSE CA</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>GOOGLE *YouTube Videos g.co/helppay# CA</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>GONG CHA - FREMONT COR FREMONT         CA</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>GROUPON INC            GROUPON.COM IL</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>WM SUPERCENTER #5606 WOODLAND CA</td>\n",
       "      <td>6.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>SOURDOUGH &amp; CO DAVIS DAVIS            CA</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>SOURDOUGH &amp; CO DAVIS DAVIS         CA</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             description  \\\n",
       "1941              EIG*BLUEHOST.COM   888-4014678 UT                                        \n",
       "1848    GLANBIA PERFORMANCE AURORA                     IL                                  \n",
       "2539  5401      PROV CR Groupon, Inc.       312-28864                                      \n",
       "2435            GUM.CO/CC* CURTIS EINS HTTPSGUMROAD. CA                                    \n",
       "2567            FH* BLUE PLANET ADVENT WWW.BLUEPLANE CO                                    \n",
       "1764  UQ MILPITAS US0048 MILPITAS                CA                                        \n",
       "1493         ERENTERPLAN1889 INSURA 888-205-8118 TX                                        \n",
       "708                  USPS PO 0585860456 WOODLAND CA                                        \n",
       "1557                    THE UPS STORE 0533 WOODLAND CA                                     \n",
       "446                     PCCD - MERRITT       OAKLAND     CA                                \n",
       "2552               POP ID          CANOGA PARK CA                                          \n",
       "1272                 THE UPS STORE 0533 WOODLAND CA                                        \n",
       "597                       T4 CJ         OAKLAND         CA                                 \n",
       "1053                   WM SUPERCENTER #5606 WOODLAND CA                                    \n",
       "1539                    WM SUPERCENTER #5606 WOODLAND CA                                   \n",
       "795                  RITE AID STORE - 6048 DAVIS     CA                                    \n",
       "1285                 GOOGLE *YouTube Videos g.co/helppay# CA                               \n",
       "971                 GOOGLE *YouTube Videos g.co/helppay# CA                                \n",
       "1294                 GOOGLE *YouTube Videos g.co/helppay# CA                               \n",
       "1735           GOOGLE *YouTube Videos g.co/helppay# CA                                     \n",
       "1695               BAY STREET GARAGE         EMERYVILLE CA                                 \n",
       "2348      ALAMEDACOCLERKRECORDER 801-9994323 UT                                            \n",
       "2033                 LION FOOD CENTER        NEWARK     CA                                 \n",
       "814                  RITE AID STORE - 6048 DAVIS     CA                                    \n",
       "1733               MATHPIX, INC.       9172976199 NY                                       \n",
       "1751                    MATHPIX, INC.     MATHPIX.COM NY                                   \n",
       "1839  GOOGLE* YouTube Videos 650-2530000 CA                                                \n",
       "1263                 GOOGLE *YouTube Videos g.co/helppay# CA                               \n",
       "1753                    MUNIMOBILE-SFMTA       415-701-2311 TX                             \n",
       "1639       MUNIMOBILE-SFMTA      415-701-2311 TX                                           \n",
       "2173         COUNTY OF LA BEACHES & MARINA DEL RE CA                                       \n",
       "936                  WALGREENS #4107       WOODLAND CA                                     \n",
       "1080                 RITE AID STORE - 6048 DAVIS       CA                                  \n",
       "569                       POSH BAGEL         DAVIS        CA                               \n",
       "2458                 TACO BELL 30771        SAN RAMON CA                                   \n",
       "2150        INDO CHINA MARKET    GOLETA      CA                                            \n",
       "2263                 DENNY'S #7888       FREMONT      CA                                   \n",
       "2261                 GONG CHA - FREMONT COR FREMONT           CA                           \n",
       "2224                 GONG CHA - FREMONT COR FREMONT             CA                         \n",
       "1980       ARIA PRINTING AND SHIP FREMONT        CA                                        \n",
       "1098                 RITE AID STORE - 6048 DAVIS       CA                                  \n",
       "2499                 LION FOOD CENTER     MILPITAS CA                                      \n",
       "954                 RITE AID STORE - 6048 DAVIS       CA                                   \n",
       "2112        H MART - SAN JOSE   SAN JOSE CA                                                \n",
       "1934        GOOGLE *YouTube Videos g.co/helppay# CA                                        \n",
       "2286                GONG CHA - FREMONT COR FREMONT         CA                              \n",
       "2236                 GROUPON INC            GROUPON.COM IL                                 \n",
       "1613                    WM SUPERCENTER #5606 WOODLAND CA                                   \n",
       "985                 SOURDOUGH & CO DAVIS DAVIS            CA                               \n",
       "1002                    SOURDOUGH & CO DAVIS DAVIS         CA                              \n",
       "\n",
       "      amount  \n",
       "1941 -395.28  \n",
       "1848  -33.86  \n",
       "2539  -33.04  \n",
       "2435  -30.00  \n",
       "2567  -26.58  \n",
       "1764  -22.04  \n",
       "1493   -0.64  \n",
       "708     0.49  \n",
       "1557    1.11  \n",
       "446     2.00  \n",
       "2552    2.31  \n",
       "1272    2.54  \n",
       "597     3.00  \n",
       "1053    3.21  \n",
       "1539    3.22  \n",
       "795     3.78  \n",
       "1285    3.99  \n",
       "971     3.99  \n",
       "1294    3.99  \n",
       "1735    3.99  \n",
       "1695    4.00  \n",
       "2348    4.38  \n",
       "2033    4.49  \n",
       "814     4.64  \n",
       "1733    4.99  \n",
       "1751    4.99  \n",
       "1839    4.99  \n",
       "1263    4.99  \n",
       "1753    5.00  \n",
       "1639    5.00  \n",
       "2173    5.00  \n",
       "936     5.17  \n",
       "1080    5.40  \n",
       "569     5.41  \n",
       "2458    5.42  \n",
       "2150    5.45  \n",
       "2263    5.50  \n",
       "2261    5.50  \n",
       "2224    5.50  \n",
       "1980    5.52  \n",
       "1098    5.66  \n",
       "2499    5.70  \n",
       "954     5.94  \n",
       "2112    5.99  \n",
       "1934    5.99  \n",
       "2286    6.00  \n",
       "2236    6.00  \n",
       "1613    6.19  \n",
       "985     6.23  \n",
       "1002    6.23  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(set(total_transactions_df.loc[\n",
    "#     total_transactions_df['category'].isna(),\n",
    "#     'description'\n",
    "# ]))\n",
    "total_transactions_df.loc[\n",
    "    total_transactions_df['category'].isna(),\n",
    "    ['description', 'amount']\n",
    "].sort_values(by='amount').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1CAyyf2kr-pS7LNX1a_0ithw6niL3Js3K4ZEOlwDViZY',\n",
       " 'replies': [{}]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = gspread.service_account()\n",
    "finance_tracker_db_spreadsheet = gc.open_by_key(SPREADSHEET_KEY)\n",
    "east_west_bank_credit_card_statements_worksheet = finance_tracker_db_spreadsheet.worksheet('east_west_bank_credit_card_statements')\n",
    "east_west_bank_credit_card_statements_worksheet.update([total_transactions_df.columns.values.tolist()] + total_transactions_df.values.tolist())\n",
    "east_west_bank_credit_card_statements_worksheet.format(\"D:D\", {\"numberFormat\": {\"type\": \"CURRENCY\"}})\n",
    "east_west_bank_credit_card_statements_worksheet.format(\"A:B\", {\"numberFormat\": {\"type\": \"DATE_TIME\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCOVER_CREDIT_CARD_STATEMENTS_FILE_PATH='/Users/jaredyu/Desktop/finances/finance_tracker_app/data/credit_card_statements/discover'\n",
    "statement_filename_list = os.listdir(DISCOVER_CREDIT_CARD_STATEMENTS_FILE_PATH)\n",
    "df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        DISCOVER_CREDIT_CARD_STATEMENTS_FILE_PATH,\n",
    "        statement_filename_list[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1CAyyf2kr-pS7LNX1a_0ithw6niL3Js3K4ZEOlwDViZY',\n",
       " 'replies': [{}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = gspread.service_account()\n",
    "finance_tracker_db_spreadsheet = gc.open_by_key(SPREADSHEET_KEY)\n",
    "east_west_bank_credit_card_statements_worksheet = finance_tracker_db_spreadsheet.worksheet('discover_credit_card_statements')\n",
    "east_west_bank_credit_card_statements_worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
    "east_west_bank_credit_card_statements_worksheet.format(\"D:D\", {\"numberFormat\": {\"type\": \"CURRENCY\"}})\n",
    "east_west_bank_credit_card_statements_worksheet.format(\"A:B\", {\"numberFormat\": {\"type\": \"DATE_TIME\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum(df['Amount']), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance_tracker_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
